# /// script
# requires-python = ">=3.12"
# dependencies = [
#     "polars",
#     "xlsxwriter",
# ]
# ///

import polars as pl
from pathlib import Path
import json
import re

# =========================
# 1. CHARGEMENT DES DONNÃ‰ES
# =========================
def charger_donnees() -> pl.DataFrame:
    """
    Charge les donnÃ©es d'annonces automobiles depuis le fichier JSON brut rÃ©cupÃ©rÃ© lors du scraping.

    Cette fonction lit le fichier JSON contenant les annonces issues
    d'AutoScout24 et retourne les donnÃ©es sous forme de DataFrame Polars.
    En cas d'erreur lors de la lecture (fichier manquant, format invalide, etc.),
    un DataFrame vide est retournÃ© et un message d'erreur est affichÃ©.

    Returns
    -------
    pl.DataFrame
        DataFrame Polars contenant les annonces automobiles si la lecture
        rÃ©ussit, sinon un DataFrame vide.
    """
    try:
        return pl.read_json("data/raw/annonces_autoscout24.json")
    except Exception as e:
        print(f"Erreur de lecture : {e}")
        return pl.DataFrame()

# =========================
# 2. NETTOYAGE NUMÃ‰RIQUE
# =========================
def nettoyer_numeriques(df: pl.DataFrame) -> pl.DataFrame:
    """
    Nettoie et standardise les colonnes numÃ©riques issues des donnÃ©es brutes.

    Cette fonction traite les colonnes 'prix' et 'kilometrage' en supprimant
    tous les caractÃ¨res non numÃ©riques, puis en les convertissant en entiers.
    Elle applique ensuite un filtre pour exclure les annonces dont le prix est
    nul, manquant ou manifestement incohÃ©rent (infÃ©rieur ou Ã©gal Ã  100).

    Parameters
    ----------
    df : pl.DataFrame
        DataFrame Polars contenant les donnÃ©es brutes des annonces automobiles.

    Returns
    -------
    pl.DataFrame
        DataFrame Polars nettoyÃ©, avec des colonnes numÃ©riques typÃ©es et
        des annonces Ã  prix non cohÃ©rent exclues.
    """
    for col in ["prix", "kilometrage"]:
        df = df.with_columns(
            pl.col(col).cast(pl.Utf8).str.replace_all(r"[^\d]", "")
            .cast(pl.Int64, strict=False)
        )
    return df.filter((pl.col("prix").is_not_null()) & (pl.col("prix") > 100))

# =========================
# 3. RÃ‰PARATION MARQUE/MODÃˆLE
# =========================
def reparer_marque_modele(df: pl.DataFrame) -> pl.DataFrame:
    """
    Normalise et fiabilise les informations de marque et de modÃ¨le des annonces.

    Cette fonction corrige les incohÃ©rences de saisie liÃ©es aux marques
    automobiles (variantes d'Ã©criture, casse, abrÃ©viations) en s'appuyant
    sur un rÃ©fÃ©rentiel de marques standardisÃ©es. Elle extrait la marque
    depuis le champ textuel d'origine, puis nettoie le modÃ¨le en supprimant
    les informations techniques parasites (motorisation, puissance, cylindrÃ©e).

    Parameters
    ----------
    df : pl.DataFrame
        DataFrame Polars contenant au minimum une colonne 'marque' issue
        des donnÃ©es brutes d'annonces automobiles.

    Returns
    -------
    pl.DataFrame
        DataFrame Polars avec deux colonnes normalisÃ©es :
        - 'marque' : marque canonique standardisÃ©e,
        - 'modele' : modÃ¨le nettoyÃ© et homogÃ©nÃ©isÃ©.
        Les annonces dont la marque n'a pas pu Ãªtre identifiÃ©e sont exclues.
    """
    marques_ref = {
        "Alfa Romeo": ["Alfa Romeo", "Alfa", "Alfa-Romeo"],
        "Aston Martin": ["Aston Martin", "Aston"],
        "Audi": ["Audi"],
        "Bentley": ["Bentley"],
        "BMW": ["BMW", "Bmw"],
        "Bugatti": ["Bugatti"],
        "Cadillac": ["Cadillac"],
        "Chevrolet": ["Chevrolet", "Chevy"],
        "Chrysler": ["Chrysler"],
        "CitroÃ«n": ["Citroen", "CitroÃ«n"],
        "Cupra": ["Cupra"],
        "Dacia": ["Dacia"],
        "Daihatsu": ["Daihatsu"],
        "Dodge": ["Dodge"],
        "DS": ["DS", "DS Automobiles"],
        "Ferrari": ["Ferrari"],
        "Fiat": ["Fiat"],
        "Ford": ["Ford"],
        "Genesis": ["Genesis"],
        "Honda": ["Honda"],
        "Hummer": ["Hummer"],
        "Hyundai": ["Hyundai"],
        "Infiniti": ["Infiniti"],
        "Isuzu": ["Isuzu"],
        "Jaguar": ["Jaguar"],
        "Jeep": ["Jeep"],
        "Kia": ["Kia"],
        "Lada": ["Lada"],
        "Lamborghini": ["Lamborghini"],
        "Lancia": ["Lancia"],
        "Land Rover": ["Land Rover", "Landrover", "Land-Rover"],
        "Lexus": ["Lexus"],
        "Lotus": ["Lotus"],
        "Maserati": ["Maserati"],
        "Mazda": ["Mazda"],
        "McLaren": ["McLaren", "Mclaren"],
        "Mercedes-Benz": ["Mercedes-Benz", "Mercedes", "Mercedes Benz"],
        "MG": ["MG", "Mg"],
        "Mini": ["Mini", "MINI"],
        "Mitsubishi": ["Mitsubishi"],
        "Nissan": ["Nissan"],
        "Opel": ["Opel"],
        "Peugeot": ["Peugeot"],
        "Polestar": ["Polestar"],
        "Porsche": ["Porsche"],
        "Renault": ["Renault"],
        "Rolls-Royce": ["Rolls-Royce", "Rolls Royce", "Rollsroyce"],
        "Saab": ["Saab"],
        "Seat": ["Seat", "SEAT"],
        "Skoda": ["Skoda", "Å koda"],
        "Smart": ["Smart", "SMART"],
        "SsangYong": ["SsangYong", "Ssangyong"],
        "Subaru": ["Subaru"],
        "Suzuki": ["Suzuki"],
        "Tesla": ["Tesla"],
        "Toyota": ["Toyota"],
        "Volkswagen": ["Volkswagen", "VW"],
        "Volvo": ["Volvo"],
        "Omoda": ["Omoda"],
        "BYD": ["BYD"],
        "Lynk & Co": ["Lynk & Co", "Lynk&Co", "Lynk"],
        "Aiways": ["Aiways"],
        "Nio": ["Nio", "NIO"],
        "Rivian": ["Rivian"],
        "Lucid": ["Lucid"],
        "Fisker": ["Fisker"]}
    
    all_variants = []
    for variants in marques_ref.values():
        all_variants.extend(variants)
    
    variant_to_canonical = {}
    for canonical, variants in marques_ref.items():
        for variant in variants:
            variant_to_canonical[variant.lower()] = canonical
    
    regex_str = f"(?i)({'|'.join(all_variants)})"

    df_temp = df.with_columns([
        pl.col("marque").str.extract(regex_str, 1).alias("marque_extracted")
    ])

    # 1. On identifie les colonnes Ã  supprimer qui existent rÃ©ellement dans le DF
    cols_to_drop = ["marque", "marque_extracted"]
    if "modele" in df.columns:
        cols_to_drop.append("modele")

    # 2. On applique le drop et le rename
    return df_temp.with_columns([
        pl.col("marque_extracted")
        .str.to_lowercase()
        .replace(variant_to_canonical)
        .alias("marque_clean"),
        
        pl.col("marque")
        .str.replace(regex_str, "")
        .str.replace_all(r"(?i)(TDI|TDCi|TGDI|TSI|CRDi|crdi|HDI|VTi|1\.2|1\.4|1\.6|2\.0|kW|CH|CV)", "")
        .str.strip_chars()
        .str.split(" ").list.slice(0, 2).list.join(" ")
        .str.strip_chars()
        .alias("modele_clean")
    ]).drop(cols_to_drop) \
      .rename({
        "marque_clean": "marque", 
        "modele_clean": "modele"
    }).filter(
        pl.col("marque").is_not_null()
    )

# =========================
# 4. IDENTIFICATION MODÃˆLE (JSON)
# =========================
def charger_modeles_json() -> dict:
    """
    Charge un rÃ©fÃ©rentiel de modÃ¨les de vÃ©hicules depuis un fichier JSON.

    Le fichier JSON est structurÃ© sous la forme d'une liste d'objets,
    chacun contenant une marque ("Make") et la liste des modÃ¨les associÃ©s
    ("Models"). Les marques sont normalisÃ©es en minuscules afin de
    faciliter les correspondances avec les donnÃ©es d'annonces nettoyÃ©es.

    En cas d'absence du fichier ou d'erreur de lecture, la fonction retourne
    un dictionnaire vide.

    Returns
    -------
    dict[str, list[str]]
        Dictionnaire associant chaque marque (en minuscules) Ã  la liste
        de ses modÃ¨les officiels.
    """
    json_path = Path("data/references/vehicle_models_merged.json")
    if not json_path.exists():
        print(f"âŒ Fichier introuvable: {json_path}")
        return {}
    
    try:
        with open(json_path, "r", encoding="utf-8") as f:
            data = json.load(f)
        
        modeles_par_marque = {}
        for item in data:
            make = item.get("Make", "").strip().lower()
            models = item.get("Models", [])
            
            if make and models:
                existing_models = modeles_par_marque.get(make, [])
                modeles_par_marque[make] = list(set(existing_models + [m.strip() for m in models if m.strip()]))
        
        print(f"âœ… JSON chargÃ© avec succÃ¨s: {len(modeles_par_marque)} marques")
        return modeles_par_marque
        
    except json.JSONDecodeError as e:
        print(f"âŒ Erreur JSON: {e}")
        return {}
    except Exception as e:
        print(f"âš ï¸ Erreur lors du chargement: {e}")
        return {}


def identifier_modele(marque: str, modele_complet: str, modeles_dict: dict) -> tuple:
    """
    Identifie le modÃ¨le canonique d'un vÃ©hicule Ã  partir d'une chaÃ®ne descriptive.

    Cette fonction compare une description textuelle complÃ¨te du vÃ©hicule
    (incluant Ã©ventuellement des variantes, finitions ou informations techniques)
    Ã  un rÃ©fÃ©rentiel de modÃ¨les associÃ© Ã  une marque donnÃ©e. L'identification
    repose sur une normalisation des chaÃ®nes et une recherche tolÃ©rante aux
    variations de format (espaces, tirets, caractÃ¨res spÃ©ciaux).

    Lorsque plusieurs correspondances sont possibles, le modÃ¨le le plus long
    est privilÃ©giÃ© afin d'Ã©viter les faux positifs (ex. "595 Competizione"
    avant "595").

    Parameters
    ----------
    marque : str
        Marque du vÃ©hicule, prÃ©alablement nettoyÃ©e et normalisÃ©e.
    modele_complet : str
        LibellÃ© complet du modÃ¨le tel qu'extrait de l'annonce.
    modeles_dict : dict
        Dictionnaire de rÃ©fÃ©rence associant chaque marque Ã  la liste
        de ses modÃ¨les officiels.

    Returns
    -------
    tuple
        Tuple de la forme (modele_identifie, reste_libelle, succes) oÃ¹ :
        - modele_identifie : modÃ¨le reconnu selon le rÃ©fÃ©rentiel,
        - reste_libelle : partie rÃ©siduelle du libellÃ© non utilisÃ©e
          (finition, motorisation, options),
        - succes : boolÃ©en indiquant si une correspondance fiable a Ã©tÃ© trouvÃ©e.
    """
    if not modele_complet or not marque:
        return (modele_complet or "", "", False)

    marque_lower = marque.strip().lower()
    s_orig = modele_complet.strip()
    if not s_orig:
        return ("", "", False)

    refs = modeles_dict.get(marque_lower, [])
    if not refs:
        return (s_orig, "", False)

    def norm(s: str) -> str:
        return re.sub(r"[^a-z0-9]", "", s.lower())

    s_norm = norm(s_orig)

    candidats = []
    for ref in refs:
        rn = norm(ref)
        if rn:
            candidats.append((ref, rn))

    candidats.sort(key=lambda x: len(x[1]), reverse=True)

    # Chercher TOUS les matches et prendre le PLUS LONG
    matches_valides = []
    for ref, rn in candidats:
        if rn in s_norm:
            matches_valides.append((ref, rn))
    
    if not matches_valides:
        return (s_orig, "", False)
    
    # Le premier match_valides est le plus long (grÃ¢ce au tri)
    best_ref, best_ref_norm = matches_valides[0]

    chars = [re.escape(ch) for ch in best_ref_norm]
    loose_pattern = r"(?i)" + r"[^a-z0-9]*".join(chars)

    m = re.search(loose_pattern, s_orig)
    if not m:
        return (best_ref, "", True)

    start, end = m.span()
    avant = s_orig[:start].strip()
    apres = s_orig[end:].strip()
    le_reste = f"{avant} {apres}".strip()

    return (best_ref, le_reste, True)


def raffiner_modele_csv(df: pl.DataFrame) -> pl.DataFrame:
    modeles_dict = charger_modeles_json()
    
    if not modeles_dict:
        return df.with_columns([
            pl.lit("").alias("le_reste"),
            pl.lit(False).alias("modele_identifie")
        ])
    
    def identifier_et_splitter(row):
        marque = row["marque"]
        modele = row["modele"]
        modele_id, le_reste, identifie = identifier_modele(marque, modele, modeles_dict)
        return {
            "modele": modele_id,
            "le_reste": le_reste,
            "modele_identifie": identifie
        }
    
    result = df.with_columns([
        pl.struct(["marque", "modele"])
          .map_elements(identifier_et_splitter, return_dtype=pl.Struct([
              pl.Field("modele", pl.Utf8),
              pl.Field("le_reste", pl.Utf8),
              pl.Field("modele_identifie", pl.Boolean)
          ]))
          .alias("modele_split")
    ])
    
    return result.with_columns([
        pl.col("modele_split").struct.field("modele").alias("modele"),
        pl.col("modele_split").struct.field("le_reste").alias("le_reste"),
        pl.col("modele_split").struct.field("modele_identifie").alias("modele_identifie")
    ]).drop("modele_split")
    

# =========================
# 5. EXTRACTION SPECS & LOCALISATION
# =========================
def extraire_specs_et_lieu(df: pl.DataFrame) -> pl.DataFrame:
    """
    Extrait les caractÃ©ristiques techniques et gÃ©ographiques des colonnes textuelles.

    Transforme la puissance en kW, tente une premiÃ¨re extraction de la cylindrÃ©e,
    et dÃ©compose la localisation en code postal et ville.

    Parameters
    ----------
    df : pl.DataFrame
        DataFrame contenant les colonnes 'puissance', 'modele' et 'localisation'.

    Returns
    -------
    pl.DataFrame
        DataFrame enrichi des colonnes 'puissance_kw', 'cylindree_l', 
        'code_postal', 'ville' et 'pays'.
    """
    # Liste Ã©tendue incluant Mainz, Potsdam, Quickborn et les villes secondaires
    villes_allemagne = (
    r"(?i)(Berlin|Hamburg|MÃ¼nchen|Munich|KÃ¶ln|Cologne|Frankfurt|Stuttgart|DÃ¼sseldorf|Dortmund|Essen|Leipzig|"
    r"Bremen|Dresden|Hannover|NÃ¼rnberg|Nuremberg|Duisburg|Bochum|Wuppertal|Bielefeld|Bonn|MÃ¼nster|Karlsruhe|"
    r"Mannheim|Augsburg|Wiesbaden|Gelsenkirchen|MÃ¶nchengladbach|Braunschweig|Chemnitz|Kiel|Aachen|Halle|"
    r"Magdeburg|Freiburg|Krefeld|Mainz|LÃ¼beck|Erfurt|Oberhausen|Rostock|Kassel|Hagen|SaarbrÃ¼cken|Potsdam|"
    r"Ludwigshafen|Oldenburg|OsnabrÃ¼ck|Leverkusen|Heidelberg|Solingen|Darmstadt|Herne|Neuss|Regensburg|"
    r"Paderborn|Ingolstadt|Offenbach|FÃ¼rth|WÃ¼rzburg|Ulm|Heilbronn|Pforzheim|Wolfsburg|GÃ¶ttingen|Bottrop|"
    r"Reutlingen|Koblenz|Bremerhaven|Erlangen|Bergisch|Jena|Remscheid|Trier|Recklinghausen|Zwickau|"
    r"Heidelberg|Salzgitter|Siegen|GÃ¼tersloh|Cottbus|Gera|Hildesheim|Hanau|Witten|Iserlohn|Ludwigsburg|"
    r"Esslingen|TÃ¼bingen|Ratingen|Flensburg|LÃ¼nen|Villingen|Giessen|Marl|Konstanz|Worms|Velbert|Minden|"
    r"NeumÃ¼nster|Norderstedt|Delmenhorst|Wilhelmshaven|Viersen|Gladbeck|Rheine|Detmold|Troisdorf|Castrop|"
    r"Arnsberg|Marburg|LÃ¼denscheid|Bamberg|Bayreuth|Brandenburg|Bocholt|Aschaffenburg|Landshut|Kempten|"
    r"Fulda|Aalen|Lippstadt|Herford|Kerpen|Plauen|Neu-Ulm|Weimar|DÃ¼ren|Quickborn|Pinneberg|Elmshorn)"
)
    regex_suffixes_allemands = r"(?i).*(berg|burg|furt|ingen|shafen|stadt|dorf|bach|wald|bruck|haven|stein|itz|ow|au)$"
    
    # Charger ton fichier JSON
    json_it = Path("data/references/it.json")
    with open(json_it, 'r', encoding='utf-8') as f:
        data = json.load(f)

    # Extraire les noms de villes et crÃ©er une regex gÃ©ante
    # On rÃ©cupÃ¨re "city" (ex: Milan) mais il serait sage d'ajouter aussi une version 
    # italienne si ton JSON ne l'a pas (ex: Milano)
    noms_villes = set()
    for item in data:
        noms_villes.add(item['city'])
        # Optionnel : si ton JSON est en anglais, on peut ajouter manuellement 
        # des variantes ou gÃ©rer les accents
        
    # Transformer en pattern Regex : (Rome|Milan|Naples|...)
    regex_villes_it_json = r"(?i)\b(" + "|".join(sorted(noms_villes, key=len, reverse=True)) + r")\b"
    
    sigle_it = r"(?i)\b(AG|AL|AN|AO|AP|AQ|AR|AT|AV|BA|BG|BI|BL|BN|BO|BR|BS|BT|BZ|CA|CB|CE|CH|CI|CL|CN|CO|CR|CS|CT|CZ|EN|FC|FE|FG|FI|FM|FR|GE|GO|GR|IM|IS|KR|LC|LE|LI|LO|LT|LU|MB|MC|ME|MI|MN|MO|MS|MT|NA|NO|NU|OG|OR|OT|PA|PC|PD|PE|PG|PI|PN|PO|PR|PT|PU|PV|PZ|RA|RC|RE|RI|RN|RM|RO|SA|SI|SO|SP|SR|SS|SU|SV|TA|TE|TN|TO|TP|TR|TS|TV|UD|VA|VB|VC|VE|VI|VR|VS|VT|VV)\b"
        
    return df.with_columns([
        # 1. Puissance
        pl.col("puissance").str.extract(r"(\d+)\s*kW", 1).cast(pl.Int64, strict=False).alias("puissance_kw"),

        # 2. Initialisation cylindrÃ©e
        pl.col("modele").str.extract(r"(\d+[.,]\d+)", 1).str.replace(",", ".").cast(pl.Float32, strict=False).alias("cylindree_l"),

        # 3. Extraction du Code Postal
        pl.col("localisation").str.extract(r"^(\d{4,5}(?:\s*[A-Z]{2})?)", 1).alias("code_postal"),

        # 4. Identification du PAYS
        pl.when(
            # On checke la liste issue du JSON
            pl.col("localisation").str.contains(regex_villes_it_json) | 
            # On checke la province Ã  la fin ou entre tirets
            pl.col("localisation").str.contains(sigle_it + r"$") |
            pl.col("localisation").str.contains(r"[\s\-\(]" + sigle_it + r"[\s\)]")
        ).then(pl.lit("Italie"))
        
        .when(pl.col("localisation").str.contains(r"^\d{4}\s*[A-Z]{2}"))
          .then(pl.lit("Pays-Bas"))
          
        .when(pl.col("localisation").str.contains(r"^\d{4}\s"))
          .then(pl.lit("Belgique"))
          
        # Bloc Allemagne
        .when(
            pl.col("localisation").str.contains(villes_allemagne) |
            pl.col("localisation").str.contains(regex_suffixes_allemands) | # Attrape Senftenberg, Coburg, etc.
            pl.col("localisation").str.contains(r"[ÃŸÃ¼Ã¶Ã¤ÃœÃ–Ã„]") |
            pl.col("localisation").str.contains(r"^[D|d]-\d{5}")
        ).then(pl.lit("Allemagne"))

        .when(pl.col("localisation").str.contains(r"^\d{5}\s"))
          .then(pl.lit("France"))
          
        .otherwise(None)
        .alias("pays"),

        # 5. Extraction de la Ville
        pl.col("localisation")
          .str.replace(r"^\d{4,5}(?:\s*[A-Z]{2})?\s*", "") # Vire le CP
          .str.replace(r"[\s\-\(]+[A-Z]{2}\)?$", "")      # Vire la province italienne propre (ex: - MI)
          .str.strip_chars()
          .alias("ville")
    ]).drop("localisation")

def corriger_cylindree(df: pl.DataFrame) -> pl.DataFrame:
    """
    Affiner l'extraction de la cylindrÃ©e selon des rÃ¨gles mÃ©tier spÃ©cifiques.

    Applique une logique conditionnelle :
    - Positionne Ã  0.0 pour les vÃ©hicules Ã©lectriques.
    - Utilise les codes modÃ¨les BMW (ex: 320 -> 2.0L) et Mercedes.
    - Recherche des motifs dÃ©cimaux dans le reste du libellÃ©.
    - Invalide les valeurs aberrantes (infÃ©rieures Ã  0.6L ou supÃ©rieures Ã  8.5L).

    Parameters
    ----------
    df : pl.DataFrame
        DataFrame avec les colonnes 'marque', 'modele' et 'carburant'.

    Returns
    -------
    pl.DataFrame
        DataFrame avec la colonne 'cylindree_l' corrigÃ©e et nettoyÃ©e.
    """
    # Extraire cylindrÃ©e BMW uniquement pour les modÃ¨les identifiÃ©s comme XXX (3 chiffres)
    df = df.with_columns([
        pl.when(
            (pl.col("marque").str.to_lowercase() == "bmw") &
            (pl.col("modele_identifie")) &
            (pl.col("modele").str.contains(r"^\d{3}$"))
        )
        .then(
            pl.col("modele").str.slice(-2).cast(pl.Float32, strict=False)
        )
        .otherwise(None)
        .alias("cylindree_bmw")
    ])
    
    # Extraire cylindrÃ©e Mercedes uniquement pour les modÃ¨les identifiÃ©s comme XXX (3 chiffres)
    df = df.with_columns([
        pl.when(
            pl.col("marque").str.to_lowercase() == "mercedes-benz"
        )
        .then(
            # Extraire le nombre dans le modÃ¨le (ex: "C 200" -> 200)
            pl.col("modele")
            .str.extract(r"(\d+)", 1)
            .cast(pl.Float32) / 100  # diviser par 100 pour obtenir 2.0 Ã  partir de 200
        )
        .otherwise(None)
        .alias("cylindree_mercedes")
    ])

    df = df.with_columns([
        pl.col("le_reste").str.extract(r"(\d+\.\d+)", 1).cast(pl.Float32).alias("cylindree_extraite")
    ])
    
    # Appliquer les rÃ¨gles finales (calcul de la cylindrÃ©e)
    df = df.with_columns(
        pl.when(pl.col("carburant").str.to_lowercase() == "Ã©lectrique")
          .then(0.0)

        .when(
            pl.col("cylindree_l").is_null() &
            pl.col("cylindree_bmw").is_not_null()
        )
          .then(pl.col("cylindree_bmw") / 10)
        
        .when(
            pl.col("cylindree_l").is_null() &
            pl.col("cylindree_mercedes").is_not_null()
        )
          .then(pl.col("cylindree_mercedes"))
        
        .when(
            pl.col("cylindree_l").is_null() &
            pl.col("cylindree_extraite").is_not_null()
        )
          .then(pl.col("cylindree_extraite"))

        .otherwise(pl.col("cylindree_l"))
        .alias("cylindree_l")
    )
    
    # Validation des seuils (appliquÃ©e APRÃˆS le calcul)
    df = df.with_columns(
        pl.when(
            (pl.col("cylindree_l") < 0.6) |
            (pl.col("cylindree_l") > 8.5)
        )
          .then(None)
          .otherwise(pl.col("cylindree_l"))
          .alias("cylindree_l")
    ).drop("cylindree_bmw", "cylindree_mercedes", "cylindree_extraite")

    return df

# =========================
# 6. NETTOYAGE TRANSMISSION
# =========================
def nettoyer_transmission(df: pl.DataFrame) -> pl.DataFrame:
    """
    Standardise les types de transmission.

    Ne conserve que les valeurs connues ('avant', 'arriere', '4x4') et
    remplace les autres entrÃ©es (souvent des erreurs de saisie) par null.

    Parameters
    ----------
    df : pl.DataFrame
        DataFrame avec la colonne 'transmission'.

    Returns
    -------
    pl.DataFrame
        DataFrame avec les types de transmission normalisÃ©s.
    """
    # Mapping des synonymes pour ne rien perdre
    mapping = {
        "propulsion": "arriÃ¨re",
        "arriere": "arriÃ¨re",
        "intÃ©grale": "4x4",
        "integrale": "4x4",
        "awd": "4x4",
        "quattro": "4x4"
    }
    return df.with_columns(
        pl.col("transmission")
        .str.to_lowercase()
        .str.strip_chars()
        .replace(mapping) # Remplace les synonymes
        .cast(pl.Utf8)
    ).with_columns(
        # On ne garde que les valeurs finales souhaitÃ©es
        pl.when(pl.col("transmission").is_in(["avant", "arriÃ¨re", "4x4"]))
        .then(pl.col("transmission"))
        .otherwise(None)
        .alias("transmission")
    )

# =========================
# 7. GESTION VALEURS ABERRANTES
# =========================
def traiter_valeurs_aberrantes(df: pl.DataFrame) -> pl.DataFrame:
    # On dÃ©finit les seuils de cohÃ©rence mÃ©tier
    return df.with_columns([
        # AnnÃ©e : si hors plage, on met Ã  null
        pl.when((pl.col("annee") >= 1980) & (pl.col("annee") <= 2027))
          .then(pl.col("annee"))
          .otherwise(None)
          .alias("annee"),

        # KilomÃ©trage : si nÃ©gatif ou trop Ã©levÃ©, on met Ã  null
        pl.when((pl.col("kilometrage") >= 0) & (pl.col("kilometrage") <= 500_000))
          .then(pl.col("kilometrage"))
          .otherwise(None)
          .alias("kilometrage"),

        # Puissance : si hors limites rÃ©alistes, on met Ã  null
        pl.when((pl.col("puissance_kw") >= 5) & (pl.col("puissance_kw") <= 1000))
          .then(pl.col("puissance_kw"))
          .otherwise(None)
          .alias("puissance_kw"),
          
        # Prix : (DÃ©jÃ  filtrÃ© dans nettoyer_numeriques, mais on peut sÃ©curiser ici)
        pl.when(pl.col("prix") > 100)
          .then(pl.col("prix"))
          .otherwise(None)
          .alias("prix")
    ])

# =========================
# 8. PRÃ‰PARATION ML
# =========================
def preparer_ml(df: pl.DataFrame) -> pl.DataFrame:
    return df


# =========================
# 9. MAIN
# =========================
def main():
    """
    Point d'entrÃ©e du script : exÃ©cute le pipeline complet de nettoyage.

    Ordonne les Ã©tapes de chargement, nettoyage numÃ©rique, rÃ©paration des labels,
    imputation des valeurs et export final vers un fichier Excel.
    """
    df = charger_donnees()
    if df.is_empty(): 
        return
    initial_count = df.height
    print(f"ðŸ“Š Lignes initiales : {initial_count}")

    # 1. Pipeline de transformation
    df = (
        df.pipe(nettoyer_numeriques)
          .pipe(reparer_marque_modele)
          .pipe(raffiner_modele_csv)
          .filter(pl.col("modele_identifie"))
          .pipe(extraire_specs_et_lieu)
          .pipe(nettoyer_transmission)
          .pipe(corriger_cylindree)   
          .pipe(traiter_valeurs_aberrantes)
    )
    
    # 2. Affichage des NA AVANT suppression
    null_counts = df.null_count()
    print(f"â“ Valeurs manquantes avant filtrage final : {null_counts}")
    
    # 3. Nettoyage des colonnes techniques
    df = df.drop(["lien_fiche", "puissance", "modele_identifie", "le_reste"])
    
    # 4. Filtrage des colonnes capitales
    cols_critiques = ["prix", "ville", "annee", "kilometrage", "marque", "modele"]
    df = df.drop_nulls(cols_critiques)
    
    # 5. Affichage des NA APRÃˆS suppression
    final_count = df.height
    print(f"\nâœ… Valeurs manquantes aprÃ¨s filtrage (sur {final_count} lignes) :")
    final_nulls = df.null_count()
    for col in df.columns:
        count = final_nulls[col][0]
        if count > 0:
            print(f"  - {col}: {count} ({ (count/final_count)*100:.1f}%)")
            
    print(f"ðŸ“Š Lignes filtrÃ©es : {initial_count - final_count} ({((initial_count - final_count)/initial_count)*100:.1f}%)")

    # Export en JSON (format 'records' pour avoir une liste d'objets [{}, {}])
    df.write_json("data/processed/autoscout_clean_ml.json")
    print(f"âœ… Export rÃ©ussi : {df.shape[0]} lignes.")
    print(df.head(5))


if __name__ == "__main__":
    main()

