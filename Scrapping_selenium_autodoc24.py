# /// script
# requires-python = ">=3.12"
# dependencies = [
#     "bs4",
#     "pydantic",
#     "requests",
#     "selenium",
#     "lxml",
# ]
# ///

import json
import re
from bs4 import BeautifulSoup as BS
from pydantic import BaseModel
from pathlib import Path
from selenium import webdriver
from selenium.webdriver.safari.service import Service
from selenium.webdriver.safari.options import Options
from selenium.webdriver.chrome.service import Service as ChromeService
from selenium.webdriver.chrome.options import Options as ChromeOptions
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import time

# --- Mod√®les Pydantic ---
class Voiture(BaseModel):
    lien_fiche: str | None = None
    prix: str | None = None
    marque: str | None = None
    localisation: str | None = None
    kilometrage: int | None = None
    annee: int | None = None
    carburant: str | None = None
    boite_de_vitesse: str | None = None
    transmission: str | None = None
    puissance: str | None = None
    type_de_vehicule: str | None = None
    sieges: int | None = None
    portes: int | None = None

# --- 1. R√©cup√©rer la page listage avec Selenium ---
def recupere_page_listage(url: str) -> str:
    """Ouvre la page listage AutoScout24, scrolle, et retourne le HTML."""
    print(f"üåê Ouverture de la page listage : {url}")
    dir_path = Path(".").resolve()

    if "matde" in str(dir_path):
        options = ChromeOptions()
        options.add_argument("--headless")
        options.add_argument("--no-sandbox")
        options.add_argument("--disable-dev-shm-usage")
        driver = webdriver.Chrome(service=ChromeService(), options=options)
    else:
        driver = webdriver.Safari(service=Service())
    
    try:
        driver.get(url)
        
        # Attendre que les articles se chargent
        print("‚è≥ Attente du chargement des annonces...")
        WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.TAG_NAME, "article"))
        )
        
        # Scroll pour charger plus d'annonces
        print("üìú Scroll de la page listage...")
        last_height = driver.execute_script("return document.body.scrollHeight")
        scroll_attempts = 0
        max_scrolls = 5
        
        while scroll_attempts < max_scrolls:
            driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            time.sleep(2)
            
            new_height = driver.execute_script("return document.body.scrollHeight")
            if new_height == last_height:
                break
            last_height = new_height
            scroll_attempts += 1
        
        html_content = driver.page_source
        print(f"‚úÖ Page listage r√©cup√©r√©e ({len(html_content)} caract√®res)")
        return html_content
    
    finally:
        driver.quit()

# --- 2. Extraire les URLs de la page listage ---
def extraire_urls_annonces(html_content: str) -> list[str]:
    """Extrait les URLs de toutes les annonces de la page listage."""
    soupe = BS(html_content, "lxml")
    articles = soupe.find_all("article")
    
    urls = []
    for art in articles:
        # Chercher le lien href qui commence par /offres/
        lien_tag = art.find("a", href=re.compile(r"^/offres/"))
        if lien_tag and lien_tag.get("href"):
            url_complete = "https://www.autoscout24.fr" + lien_tag["href"]
            urls.append(url_complete)
    
    print(f"üîó {len(urls)} URLs d'annonces extraites")
    return urls

# --- 3. R√©cup√©rer une page d'annonce ---
def recupere_page_annonce(driver, url: str) -> str:
    """R√©cup√®re le HTML d'une page d'annonce."""
    try:
        driver.get(url)
        
        # Attendre le chargement
        WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.TAG_NAME, "body"))
        )
        
        time.sleep(1)  # Petit d√©lai pour s'assurer que tout est charg√©
        return driver.page_source
    except Exception as e:
        print(f"‚ùå Erreur lors de la r√©cup√©ration de {url}: {e}")
        return None

# --- 4. Extraire les d√©tails d'une page d'annonce ---
def extraire_details_annonce(html_content: str, url: str) -> dict:
    """Extrait tous les d√©tails d'une page d'annonce."""
    voiture = {"lien_fiche": url}
    
    if not html_content:
        return voiture
    
    soupe = BS(html_content, "lxml")
    
    # ===== EXTRACTION PRIORITAIRE: JSON-LD Schema =====
    # AutoScout24 inclut les donn√©es structur√©es en JSON-LD
    json_ld_scripts = soupe.find_all("script", type="application/ld+json")
    json_data = None

    # Cherche le bloc JSON-LD qui contient l'offre (le premier <script> est souvent le fil d'Ariane)
    for script in json_ld_scripts:
        try:
            parsed = json.loads(script.string)
        except Exception:
            continue

        candidates = parsed if isinstance(parsed, list) else [parsed]
        for cand in candidates:
            if isinstance(cand, dict) and ("offers" in cand or cand.get("@type") == "Product"):
                json_data = cand
                break
        if json_data:
            break

    if json_data:
        try:
            # Prix
            if "offers" in json_data and "price" in json_data["offers"]:
                price = json_data["offers"]["price"]
                currency = json_data["offers"].get("priceCurrency", "EUR")
                voiture["prix"] = f"‚Ç¨ {price:,.0f}".replace(",", " ")
            
            # Location (depuis offeredBy)
            if "offers" in json_data and "offeredBy" in json_data["offers"]:
                offered_by = json_data["offers"]["offeredBy"]
                if "address" in offered_by:
                    address = offered_by["address"]
                    city = address.get("addressLocality", "")
                    postal = address.get("postalCode", "")
                    if city or postal:
                        voiture["localisation"] = f"{postal} {city}".strip()

            # Location alternative: certains sch√©mas utilisent seller ou availableAtOrFrom
            if not voiture.get("localisation") and "offers" in json_data:
                offer = json_data["offers"]
                seller = offer.get("seller") or offer.get("offeredBy")
                if seller and isinstance(seller, dict):
                    address = seller.get("address", {})
                    city = address.get("addressLocality", "")
                    postal = address.get("postalCode", "")
                    if city or postal:
                        voiture["localisation"] = f"{postal} {city}".strip()

            if not voiture.get("localisation") and "availableAtOrFrom" in json_data:
                address = json_data["availableAtOrFrom"].get("address", {})
                city = address.get("addressLocality", "")
                postal = address.get("postalCode", "")
                if city or postal:
                    voiture["localisation"] = f"{postal} {city}".strip()
            
            # Kilom√®trage
            if "itemOffered" in json_data and "mileageFromOdometer" in json_data["itemOffered"]:
                km_data = json_data["itemOffered"]["mileageFromOdometer"]
                if "value" in km_data:
                    voiture["kilometrage"] = int(km_data["value"])
            
            # Ann√©e
            if "itemOffered" in json_data and "productionDate" in json_data["itemOffered"]:
                prod_date = json_data["itemOffered"]["productionDate"]
                if prod_date:
                    year_match = re.search(r'(\d{4})', prod_date)
                    if year_match:
                        voiture["annee"] = int(year_match.group(1))
            
            # Transmission
            if "itemOffered" in json_data and "driveWheelConfiguration" in json_data["itemOffered"]:
                voiture["transmission"] = json_data["itemOffered"]["driveWheelConfiguration"]
            
            # Bo√Æte de vitesse
            if "itemOffered" in json_data and "vehicleTransmission" in json_data["itemOffered"]:
                transmission_text = json_data["itemOffered"]["vehicleTransmission"]
                if "automatique" in transmission_text.lower():
                    voiture["boite_de_vitesse"] = "Automatique"
                elif "manuelle" in transmission_text.lower():
                    voiture["boite_de_vitesse"] = "Manuelle"
                else:
                    voiture["boite_de_vitesse"] = transmission_text
            
            # Nombre de portes
            if "itemOffered" in json_data and "numberOfDoors" in json_data["itemOffered"]:
                voiture["portes"] = int(json_data["itemOffered"]["numberOfDoors"])
            
            # Type de carrosserie
            if "itemOffered" in json_data and "bodyType" in json_data["itemOffered"]:
                voiture["type_de_vehicule"] = json_data["itemOffered"]["bodyType"]
            
            # Puissance
            if "itemOffered" in json_data and "vehicleEngine" in json_data["itemOffered"]:
                engines = json_data["itemOffered"]["vehicleEngine"]
                if engines and len(engines) > 0:
                    engine = engines[0]
                    if "enginePower" in engine:
                        powers = engine["enginePower"]
                        kw = None
                        hp = None
                        for power in powers:
                            if power.get("unitCode") == "KWT":
                                kw = power.get("value")
                            elif power.get("unitCode") == "BHP":
                                hp = power.get("value")
                        if kw and hp:
                            voiture["puissance"] = f"{kw} kW ({hp} CH)"
        except Exception as e:
            print(f"‚ö†Ô∏è  Erreur lors du parsing JSON-LD: {e}")
    
    # ===== EXTRACTION HTML =====
    
    # Marque/Mod√®le - chercher dans le titre principal (L'ANCIENNE M√âTHODE QUI MARCHAIT)
    titre_tag = soupe.find("h1")
    if titre_tag:
        voiture["marque"] = titre_tag.get_text(strip=True)
    
    # Prix (si pas trouv√© dans JSON)
    if not voiture.get("prix"):
        prix_tag = soupe.find("span", class_=re.compile(r"PriceInfo_price"))
        if prix_tag:
            voiture["prix"] = prix_tag.get_text(strip=True)
    
    # Localisation (si pas trouv√©e dans JSON)
    if not voiture.get("localisation"):
        # Chercher pr√®s de l'ic√¥ne de localisation
        location_links = soupe.find_all("a", href=re.compile(r"dealer.*location", re.I))
        for link in location_links:
            text = link.get_text(strip=True)
            if text and len(text) > 2:
                voiture["localisation"] = text
                break
    
    # Tous les d√©tails dans les spans et divs
    all_text = soupe.get_text()
    
    # Kilom√®trage (si pas trouv√© dans JSON)
    if not voiture.get("kilometrage"):
        km_match = re.search(r'([\d\s]+)\s*km', all_text, re.IGNORECASE)
        if km_match:
            km_str = km_match.group(1).replace(" ", "").replace("\xa0", "").replace("\u202f", "")
            try:
                voiture["kilometrage"] = int(km_str)
            except ValueError:
                pass
    
    # Ann√©e (si pas trouv√©e dans JSON)
    if not voiture.get("annee"):
        annee_match = re.search(r'(\d{2})?/?(\d{4})', all_text)
        if annee_match:
            year_str = annee_match.group(2)
            try:
                year = int(year_str)
                if 1950 <= year <= 2030:
                    voiture["annee"] = year
            except ValueError:
                pass
    
    # Carburant
    if not voiture.get("carburant"):
        carburants = ["Essence", "Diesel", "√âlectrique", "Hybride", "Gaz", "Hybrid"]
        for carb in carburants:
            if carb.lower() in all_text.lower():
                voiture["carburant"] = carb
                break
    
    # Bo√Æte de vitesse (si pas trouv√©e dans JSON)
    if not voiture.get("boite_de_vitesse"):
        if "manuelle" in all_text.lower():
            voiture["boite_de_vitesse"] = "Manuelle"
        elif "automatique" in all_text.lower():
            voiture["boite_de_vitesse"] = "Automatique"
    
    # Transmission (si pas trouv√©e dans JSON)
    if not voiture.get("transmission"):
        if "4x4" in all_text.upper():
            voiture["transmission"] = "4x4"
        elif "avant" in all_text.lower():
            voiture["transmission"] = "Avant"
        elif "arri√®re" in all_text.lower():
            voiture["transmission"] = "Arri√®re"
    
    # Puissance (si pas trouv√©e dans JSON)
    if not voiture.get("puissance"):
        puissance_match = re.search(r'([\d\s]+)\s*kW\s*\(?\s*([\d\s]+)\s*CH\)?', all_text, re.IGNORECASE)
        if puissance_match:
            voiture["puissance"] = f"{puissance_match.group(1).strip()} kW ({puissance_match.group(2).strip()} CH)"
    
    # Chercher les d√©tails dans les DataGrid (tables de caract√©ristiques)
    data_grids = soupe.find_all("dl", class_=re.compile(r"DataGrid"))
    for grid in data_grids:
        dt_tags = grid.find_all("dt")
        dd_tags = grid.find_all("dd")
        
        for dt, dd in zip(dt_tags, dd_tags):
            label = dt.get_text(strip=True).lower()
            value = dd.get_text(strip=True)
            
            # Portes (si pas trouv√© dans JSON)
            if "porte" in label and not voiture.get("portes"):
                portes_match = re.search(r'(\d+)', value)
                if portes_match:
                    voiture["portes"] = int(portes_match.group(1))
            
            # Si√®ges / Places
            if ("si√®ge" in label or "place" in label) and not voiture.get("sieges"):
                sieges_match = re.search(r'(\d+)', value)
                if sieges_match:
                    voiture["sieges"] = int(sieges_match.group(1))
            
            # Carburant (si pas trouv√©)
            if "carburant" in label and not voiture.get("carburant"):
                voiture["carburant"] = value
            
            # Transmission (si pas trouv√©e)
            if "transmission" in label and not voiture.get("transmission"):
                voiture["transmission"] = value
            
            # Bo√Æte de vitesse (si pas trouv√©e)
            if "bo√Æte" in label and not voiture.get("boite_de_vitesse"):
                voiture["boite_de_vitesse"] = value
            
            # Type de v√©hicule / Carrosserie (si pas trouv√©)
            if "carrosserie" in label and not voiture.get("type_de_vehicule"):
                voiture["type_de_vehicule"] = value
    
    return voiture

# --- 5. Sauvegarder en JSON ---
def sauvegarder_json(voitures: list[Voiture], filename: str = "annonces_autoscout24.json"):
    """Sauvegarde la liste des voitures dans un fichier JSON."""
    data = [v.model_dump() for v in voitures]
    
    filepath = Path(filename)
    with open(filepath, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2, default=str)
    
    print(f"üíæ {len(voitures)} annonces sauvegard√©es dans {filepath}")
    return filepath

# --- 6. Main ---
def main():
    # URL de base (sans page, on va l'ajouter)
    url_base = "https://www.autoscout24.fr/lst?atype=C&cy=D%2CA%2CB%2CE%2CF%2CI%2CL%2CNL&damaged_listing=exclude&desc=0&powertype=kw&search_id=k9p7elkop&sort=standard&source=listpage_pagination&ustate=N%2CU"
    
    print("üöÄ D√©marrage du scraping AutoScout24")
    print("=" * 60)
    
    # √âtape 1 : R√©cup√©rer les URLs de plusieurs pages (1 √† 5)
    print("\nüìã R√©cup√©ration des pages de listage...")
    urls_annonces_toutes = {}  # Utiliser un dict pour √©viter les doublons
    
    for page in range(1, 201):  # Pages 1 √† 200
        url_page = f"{url_base}&page={page}"
        print(f"\n--- Page {page}/200 ---")
        
        html_listage = recupere_page_listage(url_page)
        urls_page = extraire_urls_annonces(html_listage)
        
        # Ajouter au dictionnaire (les doublons seront automatiquement ignor√©s)
        for url in urls_page:
            urls_annonces_toutes[url] = True
        
        print(f"üìä Total URLs uniques jusqu'ici : {len(urls_annonces_toutes)}")
    
    # Convertir en liste
    urls_annonces = list(urls_annonces_toutes.keys())
    
    print(f"\n‚úÖ Total final : {len(urls_annonces)} annonces uniques √† scraper")
    print("=" * 60)
    
    if not urls_annonces:
        print("‚ö†Ô∏è  Aucune annonce trouv√©e")
        return
    
    # √âtape 2 : Cr√©er un driver pour consulter chaque annonce
    print(f"\nüìñ Consultation de {len(urls_annonces)} annonces...")
    print("=" * 60)
    
    dir_path = Path(".").resolve()
    if "matde" in str(dir_path):
        options = ChromeOptions()
        options.add_argument("--headless")
        options.add_argument("--no-sandbox")
        options.add_argument("--disable-dev-shm-usage")
        driver = webdriver.Chrome(service=ChromeService(), options=options)
    else:
        driver = webdriver.Safari(service=Service())
    
    try:
        liste_voitures = []
        
        for idx, url in enumerate(urls_annonces, 1):
            print(f"\n[{idx}/{len(urls_annonces)}] Traitement de {url}")
            
            # R√©cup√©rer la page d'annonce
            html_annonce = recupere_page_annonce(driver, url)
            
            if html_annonce:
                # Extraire les d√©tails
                details = extraire_details_annonce(html_annonce, url)
                
                try:
                    voiture = Voiture(**details)
                    liste_voitures.append(voiture)
                    
                    # Afficher un r√©sum√©
                    info_parts = []
                    if voiture.marque:
                        info_parts.append(voiture.marque)
                    if voiture.prix:
                        info_parts.append(voiture.prix)
                    if voiture.portes:
                        info_parts.append(f"{voiture.portes} portes")
                    if voiture.localisation:
                        info_parts.append(voiture.localisation)
                    
                    print(f"‚úÖ Annonce ajout√©e: {' - '.join(info_parts)}")
                except Exception as e:
                    print(f"‚ö†Ô∏è  Erreur validation: {e}")
            
            # Petit d√©lai entre les requ√™tes pour ne pas surcharger le serveur
            time.sleep(1)
        
        # √âtape 3 : Sauvegarder
        print("\n" + "=" * 60)
        if liste_voitures:
            sauvegarder_json(liste_voitures)
            print(f"‚ú® Scraping termin√© : {len(liste_voitures)} annonces")
        else:
            print("‚ö†Ô∏è  Aucune annonce valide trouv√©e")
    
    finally:
        driver.quit()
        print("=" * 60)

if __name__ == "__main__":
    main()