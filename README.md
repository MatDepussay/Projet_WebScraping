# ğŸš— Projet Web Scraping - PrÃ©diction de Prix AutoScout24

## ğŸ“‹ Table des matiÃ¨res

- [Objectif](#-objectif)
- [Architecture](#-architecture)
- [Installation](#-installation)
- [Utilisation](#-utilisation)
- [Structure du projet](#-structure-du-projet)
- [Pipeline de donnÃ©es](#-pipeline-de-donnÃ©es)

---

## ğŸ¯ Objectif

DÃ©velopper une application complÃ¨te de **scraping et analyse de donnÃ©es automobiles** pour estimer si le prix de vente d'une annonce AutoScout24 est cohÃ©rent avec le marchÃ©.

**FonctionnalitÃ©s principales:**
- âœ… Scraping automatisÃ© des annonces AutoScout24
- âœ… Nettoyage et normalisation des donnÃ©es
- âœ… Identification intelligente des modÃ¨les de voitures
- âœ… EntraÃ®nement de modÃ¨les ML (Random Forest & XGBoost)
- âœ… Interface Streamlit pour visualiser et analyser les donnÃ©es
- âœ… Automatisation via GitHub Actions (scraping quotidien)

---

## ğŸ—ï¸ Architecture

### Composants principaux

```
Projet_WebScraping/
â”œâ”€â”€ Voiture_app.py              # ğŸ¨ Interface Streamlit (3 onglets)
â”œâ”€â”€ cleaning.py                 # ğŸ§¹ Pipeline de nettoyage (9 Ã©tapes)
â”œâ”€â”€ MachineLearning.py          # ğŸ¤– EntraÃ®nement des modÃ¨les
â”œâ”€â”€ Scrapping_selenium_autodoc24.py  # ğŸ•·ï¸ Scraper autonome (GitHub Actions)
â”œâ”€â”€ hello.py                    # ğŸ”„ Fusion des sources de donnÃ©es
â”œâ”€â”€ vehicle_models_merged.json   # ğŸ“š RÃ©fÃ©rence des modÃ¨les de voitures
â””â”€â”€ pyproject.toml              # âš™ï¸ Configuration du projet
```

---

## ğŸ“¥ Installation

### PrÃ©requis
- Python 3.12+
- UV (package manager)

### Setup
```bash
# Cloner le projet
git clone <repo>
cd Projet_WebScraping

# Installer les dÃ©pendances
uv sync

# Optionnel: Fusionner les sources de donnÃ©es
uv run hello.py
```

---

## ğŸš€ Utilisation

### 1ï¸âƒ£ Application Streamlit (Interface utilisateur)
```bash
uv run streamlit run Voiture_app.py
```

**Trois onglets disponibles:**

| Onglet | Fonction |
|--------|----------|
| ğŸ“¥ **Scraper** | Scrape les annonces, charge JSON, ou fusionne nouvelles donnÃ©es |
| ğŸ“Š **RÃ©gression ML** | EntraÃ®ne Random Forest & XGBoost, affiche mÃ©triques |
| ğŸ” **SÃ©lectionner** | Visualise, filtre et prÃ©dit le prix des voitures |

### 2ï¸âƒ£ Nettoyage des donnÃ©es
```bash
uv run cleaning.py
```
GÃ©nÃ¨re `autoscout_clean_ml.xlsx` avec donnÃ©es nettoyÃ©es.

### 3ï¸âƒ£ EntraÃ®nement ML
```bash
uv run MachineLearning.py
```
EntraÃ®ne les 2 modÃ¨les et sauvegarde les rÃ©sultats dans `models/`.

### 4ï¸âƒ£ Scraping autonome
```bash
uv run Scrapping_selenium_autodoc24.py
```
Scrape AutoScout24 et fusionne les nouvelles annonces (utilisÃ© par GitHub Actions).

---

## ğŸ“‚ Structure du projet

### `Voiture_app.py` - Interface Streamlit
Combine scraping, nettoyage et ML dans une seule application:
- **Onglet 1:** Scraping avec dÃ©duplication par URL
- **Onglet 2:** EntraÃ®nement et comparaison des modÃ¨les ML
- **Onglet 3:** Filtrage avancÃ© et prÃ©dictions de prix

### `cleaning.py` - Pipeline de nettoyage (9 Ã©tapes)

| Ã‰tape | Fonction | DÃ©tails |
|-------|----------|---------|
| 1 | `charger_donnees()` | Charge `annonces_autoscout24.json` |
| 2 | `nettoyer_numeriques()` | Extrait prix/kilometrage, supprime nulls |
| 3 | `reparer_marque_modele()` | Normalise les marques et modÃ¨les |
| 4 | `raffiner_modele_csv()` | Identifie modÃ¨les via JSON (3 niveaux: strict/substring/fuzzy) |
| 5 | `extraire_specs_et_lieu()` | Extrait puissance, cylindrÃ©e, localisation |
| 6 | `nettoyer_transmission()` | Filtre transmission (avant/arriÃ¨re/4x4) |
| 7 | `traiter_valeurs_aberrantes()` | Imputations intelligentes par marque+modÃ¨le |
| 8 | `preparer_ml()` | PrÃ©pare les colonnes numÃ©riques |
| 9 | `main()` | ExÃ©cute le pipeline complet |

### `MachineLearning.py` - ModÃ¨les prÃ©dictifs
EntraÃ®ne 2 modÃ¨les en parallÃ¨le:

**Random Forest:**
- 200 arbres, profondeur max 15
- Ensemble randomisÃ© pour robustesse

**XGBoost:**
- 200 estimateurs, learning rate 0.1
- Optimisation gradient boostÃ©e

**MÃ©triques:**
- RMSE (erreur quadratique moyenne)
- RÂ² (coefficient de dÃ©termination)
- MAE (erreur absolue moyenne)
- Cross-validation 5-fold

### `hello.py` - Fusion des donnÃ©es
Fusionne 3 sources en un seul JSON:
- `vehicle models.json` (Wikipedia scraping)
- `EUROPEAN CARS DATASET.xlsx`
- `autoscout24-germany-dataset.csv`

**RÃ©sultat:** `vehicle_models_merged.json` (rÃ©fÃ©rence maÃ®tre)

---

## ğŸ”„ Pipeline de donnÃ©es

```
annonces_autoscout24.json
        â†“
    cleaning.py
   (9 Ã©tapes)
        â†“
   autoscout_clean_ml.xlsx
        â†“
   MachineLearning.py
        â†“
   PrÃ©dictions de prix
```

### Ã‰tapes clÃ©s du nettoyage

1. **Extraction numÃ©rique:** `"12 500 â‚¬"` â†’ `12500`
2. **Normalisation marques:** `"Alfa" â†’ "Alfa Romeo"`
3. **Identification modÃ¨les:** 
   - Niveau 1 (strict): `"M5 CS"` â†’ `"M5"` âœ“
   - Niveau 2 (substring): `"C31.1 Seduction"` â†’ `"C3"` âœ“
   - Niveau 3 (fuzzy): `"AygoAygo"` â†’ `"Aygo"` âœ“
4. **Imputations intelligentes:** Remplace valeurs aberrantes par moyennes (marque+modÃ¨le)
5. **One-Hot Encoding:** Variables catÃ©gorielles â†’ numÃ©riques

---

## ğŸ“Š RÃ©sultats attendus

### Machine Learning
- **MÃ©triques:** RMSE < â‚¬10k, RÂ² > 0.75
- **Features importantes:** Marque, modÃ¨le, annÃ©e, kilomÃ©trage
- **PrÃ©dictions:** Estimations de prix par catÃ©gorie

### DonnÃ©es
- **Avant nettoyage:** ~6500 annonces
- **AprÃ¨s filtrage:** ~2600 annonces (modÃ¨les identifiÃ©s)
- **Couverture:** 100+ marques automobiles

---

## âš™ï¸ Configuration (GitHub Actions)

**Workflow quotidien:** 3 AM UTC (chaque jour)
- Lance le scraper autonome
- Fusionne les nouvelles annonces
- ExÃ©cute le nettoyage
- EntraÃ®ne les modÃ¨les ML

---

## ğŸ“ Notes techniques

### Encodages gÃ©rÃ©s
- Excel: Lectures multi-encodages (cp1252, utf-8, latin-1, etc.)
- JSON: UTF-8 standard
- CSV: DÃ©tection automatique

### Polars vs Pandas
- **Polars:** Scraping + nettoyage (performance)
- **Pandas:** ML (sklearn compatibility)

### DÃ©pendances principales
```
polars          # DataFrames haute performance
scikit-learn    # ML classique
xgboost         # Gradient boosting
selenium        # Web scraping
streamlit       # Interface web
pydantic        # Validation
```

---

## ğŸ”— Fichiers clÃ©s

| Fichier | Taille | RÃ´le |
|---------|--------|------|
| `annonces_autoscout24.json` | ~10 MB | DonnÃ©es brutes scrappÃ©es |
| `autoscout_clean_ml.xlsx` | ~5 MB | DonnÃ©es nettoyÃ©es |
| `vehicle_models_merged.json` | ~500 KB | RÃ©fÃ©rence de modÃ¨les |
| `models/random_forest_model.pkl` | ~50 MB | ModÃ¨le Random Forest |
| `models/xgboost_model.pkl` | ~20 MB | ModÃ¨le XGBoost |

---

## ğŸ“§ Contact

Projet rÃ©alisÃ© dans le cadre du Master 2 - Janvier 2026